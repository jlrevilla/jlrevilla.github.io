<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Una arquitectura para analítica sobre data de microservicios en CosmosDB | Metaverso de JL</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Una arquitectura para analítica sobre data de microservicios en CosmosDB" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Escenario: Tenemos una aplicación moderna en Azure que usa múltiples microservicios y requiere una latencia de milisegundos. Si bien la magia de la app en sí la tienen resuelta los arquitectos que la diseñaron, lo que toca ahora es analizar la mejor manera de analizar la data. Por la forma en la que ha sido pensada esta aplicación, cada microservicio cuenta con su propia base de datos Cosmos DB, lo quiere decir que por diseño no existe consitencia entre estas diversas bases de datos… y eso está bien, pues cada Cosmos solo sabe lo que debe saber para atender a su microservicio. Por otro lado, por temas de economía, los datos en Cosmos DB tienen un TTL de 30 días y solo guardan el último mes de las transacciones. Es por estos motivos que existe la necesidad de consolidar la información para analítica y, al mismo tiempo, para que sirva de fuente al equipo de soporte a los usuarios. Solución: Aprovechar la funcionalidad de Change Feed en Cosmos DB para agregar cada una de las transacciones realizadas en dos destinos: Un SQL Server que soportará los queries de los usuarios de soporte y aquellos reportes operativos más clásicos, y un almacenamiento tipo Azure Data Lake Storage que guardará toda la información generada por la aplicación en formato parquet. Aquí nuestro fiel Databricks se encargará de prepararla, limpiarla y depositarla en un pool dentro de Azure Synapse para los usuarios de analítica por SQL o Spark. Optimización: Esta primera arquitectura funciona muy bien pero siempre puede mejorarse. En particular buscamos sacarle provecho a nuevas funcionalidades de los productos en Azure, como es el caso de Synapse Link, para simplificar la arquitectura. Los Cosmos DB entonces crearán réplicas columnares usando la característica de Analytical Stores que estarán expuestas directamente en Synapse, sin un proceso de ETL, en tiempo real. Ahora, ¿podemos optimizar en algo o aprocechar mejor la data en el ADLS? Pues si, gracias a Query Acceleration y aprovechando el código en el que viene trabajando Pablo Mugica y su nodbdb, ahora las consultas sencillas de soporte pueden responderse haciendo queries directamente al storage. Y es así como se ve ahora… en el papel. Les cuento cuando la tengamos funcionando." />
<meta property="og:description" content="Escenario: Tenemos una aplicación moderna en Azure que usa múltiples microservicios y requiere una latencia de milisegundos. Si bien la magia de la app en sí la tienen resuelta los arquitectos que la diseñaron, lo que toca ahora es analizar la mejor manera de analizar la data. Por la forma en la que ha sido pensada esta aplicación, cada microservicio cuenta con su propia base de datos Cosmos DB, lo quiere decir que por diseño no existe consitencia entre estas diversas bases de datos… y eso está bien, pues cada Cosmos solo sabe lo que debe saber para atender a su microservicio. Por otro lado, por temas de economía, los datos en Cosmos DB tienen un TTL de 30 días y solo guardan el último mes de las transacciones. Es por estos motivos que existe la necesidad de consolidar la información para analítica y, al mismo tiempo, para que sirva de fuente al equipo de soporte a los usuarios. Solución: Aprovechar la funcionalidad de Change Feed en Cosmos DB para agregar cada una de las transacciones realizadas en dos destinos: Un SQL Server que soportará los queries de los usuarios de soporte y aquellos reportes operativos más clásicos, y un almacenamiento tipo Azure Data Lake Storage que guardará toda la información generada por la aplicación en formato parquet. Aquí nuestro fiel Databricks se encargará de prepararla, limpiarla y depositarla en un pool dentro de Azure Synapse para los usuarios de analítica por SQL o Spark. Optimización: Esta primera arquitectura funciona muy bien pero siempre puede mejorarse. En particular buscamos sacarle provecho a nuevas funcionalidades de los productos en Azure, como es el caso de Synapse Link, para simplificar la arquitectura. Los Cosmos DB entonces crearán réplicas columnares usando la característica de Analytical Stores que estarán expuestas directamente en Synapse, sin un proceso de ETL, en tiempo real. Ahora, ¿podemos optimizar en algo o aprocechar mejor la data en el ADLS? Pues si, gracias a Query Acceleration y aprovechando el código en el que viene trabajando Pablo Mugica y su nodbdb, ahora las consultas sencillas de soporte pueden responderse haciendo queries directamente al storage. Y es así como se ve ahora… en el papel. Les cuento cuando la tengamos funcionando." />
<link rel="canonical" href="http://localhost:4000/tech/2020/11/29/CosmosDB-hacia-Synapse/" />
<meta property="og:url" content="http://localhost:4000/tech/2020/11/29/CosmosDB-hacia-Synapse/" />
<meta property="og:site_name" content="Metaverso de JL" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-29T21:22:36-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Una arquitectura para analítica sobre data de microservicios en CosmosDB" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/tech/2020/11/29/CosmosDB-hacia-Synapse/"},"url":"http://localhost:4000/tech/2020/11/29/CosmosDB-hacia-Synapse/","description":"Escenario: Tenemos una aplicación moderna en Azure que usa múltiples microservicios y requiere una latencia de milisegundos. Si bien la magia de la app en sí la tienen resuelta los arquitectos que la diseñaron, lo que toca ahora es analizar la mejor manera de analizar la data. Por la forma en la que ha sido pensada esta aplicación, cada microservicio cuenta con su propia base de datos Cosmos DB, lo quiere decir que por diseño no existe consitencia entre estas diversas bases de datos… y eso está bien, pues cada Cosmos solo sabe lo que debe saber para atender a su microservicio. Por otro lado, por temas de economía, los datos en Cosmos DB tienen un TTL de 30 días y solo guardan el último mes de las transacciones. Es por estos motivos que existe la necesidad de consolidar la información para analítica y, al mismo tiempo, para que sirva de fuente al equipo de soporte a los usuarios. Solución: Aprovechar la funcionalidad de Change Feed en Cosmos DB para agregar cada una de las transacciones realizadas en dos destinos: Un SQL Server que soportará los queries de los usuarios de soporte y aquellos reportes operativos más clásicos, y un almacenamiento tipo Azure Data Lake Storage que guardará toda la información generada por la aplicación en formato parquet. Aquí nuestro fiel Databricks se encargará de prepararla, limpiarla y depositarla en un pool dentro de Azure Synapse para los usuarios de analítica por SQL o Spark. Optimización: Esta primera arquitectura funciona muy bien pero siempre puede mejorarse. En particular buscamos sacarle provecho a nuevas funcionalidades de los productos en Azure, como es el caso de Synapse Link, para simplificar la arquitectura. Los Cosmos DB entonces crearán réplicas columnares usando la característica de Analytical Stores que estarán expuestas directamente en Synapse, sin un proceso de ETL, en tiempo real. Ahora, ¿podemos optimizar en algo o aprocechar mejor la data en el ADLS? Pues si, gracias a Query Acceleration y aprovechando el código en el que viene trabajando Pablo Mugica y su nodbdb, ahora las consultas sencillas de soporte pueden responderse haciendo queries directamente al storage. Y es así como se ve ahora… en el papel. Les cuento cuando la tengamos funcionando.","headline":"Una arquitectura para analítica sobre data de microservicios en CosmosDB","dateModified":"2020-11-29T21:22:36-05:00","datePublished":"2020-11-29T21:22:36-05:00","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Metaverso de JL" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Metaverso de JL</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Una arquitectura para analítica sobre data de microservicios en CosmosDB</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-11-29T21:22:36-05:00" itemprop="datePublished">Nov 29, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><strong>Escenario</strong>: Tenemos una aplicación moderna en Azure que usa múltiples microservicios y requiere una latencia de milisegundos. Si bien la magia de la app en sí la tienen resuelta los arquitectos que la diseñaron, lo que toca ahora es analizar la mejor manera de analizar la data.</p>

<p>Por la forma en la que ha sido pensada esta aplicación, cada microservicio cuenta con su propia base de datos Cosmos DB, lo quiere decir que por diseño no existe consitencia entre estas diversas bases de datos… y eso está bien, pues cada Cosmos solo sabe lo que debe saber para atender a su microservicio. Por otro lado, por temas de economía, los datos en Cosmos DB tienen un TTL de 30 días y solo guardan el último mes de las transacciones. Es por estos motivos que existe la necesidad de consolidar la información para analítica y, al mismo tiempo, para que sirva de fuente al equipo de soporte a los usuarios.</p>

<p><strong>Solución</strong>: Aprovechar la funcionalidad de Change Feed en Cosmos DB para agregar cada una de las transacciones realizadas en dos destinos: Un SQL Server que soportará los queries de los usuarios de soporte y aquellos reportes operativos más clásicos, y un almacenamiento tipo Azure Data Lake Storage que guardará toda la información generada por la aplicación en formato parquet. Aquí nuestro fiel Databricks se encargará de prepararla, limpiarla y depositarla en un pool dentro de Azure Synapse para los usuarios de analítica por SQL o Spark.</p>

<p><img src="/img/CosmosDB to Synapse (Original).jpg" alt="Arquitectura antigua" /></p>

<p><strong>Optimización</strong>: Esta primera arquitectura funciona muy bien pero siempre puede mejorarse. En particular buscamos sacarle provecho a nuevas funcionalidades de los productos en Azure, como es el caso de Synapse Link, para simplificar la arquitectura.</p>

<p>Los Cosmos DB entonces crearán réplicas columnares usando la característica de <a href="https://docs.microsoft.com/en-us/azure/cosmos-db/analytical-store-introduction">Analytical Stores</a> que estarán expuestas directamente en Synapse, sin un proceso de ETL, en tiempo real. Ahora, ¿podemos optimizar en algo o aprocechar mejor la data en el ADLS? Pues si, gracias a <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-query-acceleration">Query Acceleration</a> y aprovechando el código en el que viene trabajando Pablo Mugica y su <a href="https://github.com/PabloMugica/nodbdb">nodbdb</a>, ahora las consultas sencillas de soporte pueden responderse haciendo queries directamente al storage.</p>

<p><img src="/img/CosmosDB to Synapse (New).jpg" alt="Arquitectura nueva" /></p>

<p>Y es así como se ve ahora… en el papel. Les cuento cuando la tengamos funcionando.</p>

  </div><a class="u-url" href="/tech/2020/11/29/CosmosDB-hacia-Synapse/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Metaverso de JL</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Metaverso de JL</li><li><a class="u-email" href="mailto:jl@revilla.pe">jl@revilla.pe</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jlrevilla"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jlrevilla</span></a></li><li><a href="https://www.twitter.com/jlrevilla"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jlrevilla</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>JL Revilla | Gen X | Whovian | Browncoat</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
